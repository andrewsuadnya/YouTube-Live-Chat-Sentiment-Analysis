# ğŸ“± YouTube Live Chat Sentiment Analysis (Near Real-Time Data Pipeline)

A near real-time system for ingesting, processing, and analyzing YouTube Live Chat comments using modern Big Data technologies. Built using **Apache Kafka**, **Spark Structured Streaming**, **Elasticsearch**, **Kibana**, **React.js**, and **Flask**, this pipeline performs sentiment analysis using **VADER** and **TextBlob**, and visualizes results on an interactive dashboard.

> âš ï¸ **Why Near Real-Time?**  
> The system is categorized as **near real-time** due to two key constraints:  
> 1. **YouTube Data API Rate Limits** â€“ The API enforces a **minimum 4-5 second polling interval** and does not support continuous real-time streaming, which limits the granularity of live chat data collection.  
> 2. **Micro-Batch Processing in Spark Structured Streaming** â€“ Spark processes data in small batches (e.g., every 2â€“5 seconds), not per individual message, resulting in slight latency between ingestion and analysis.

---

## ğŸ”§ Tech Stack

![Data Pipeline2](https://github.com/user-attachments/assets/384d4341-ddf0-4a7a-bdf2-6448aa926a3d)
The data pipeline consists of five main stages:
â‘  YouTube Live Chat is retrieved using the YouTube Data API v3 by a custom Kafka producer.
â‘¡ The messages are ingested into Apache Kafka, acting as a distributed messaging system.
â‘¢ Apache Spark Structured Streaming consumes data from Kafka, performs cleaning, transformation, and sentiment analysis (VADER & TextBlob).
â‘£ The enriched data is sent to Elasticsearch for storage and indexing.
â‘¤ Data is then visualized in near real-time via Kibana and a custom React.js + Flask dashboard using WebSockets.

* **[YouTube Data API v3](https://developers.google.com/youtube/v3)** â€“ Retrieves live chat messages from YouTube (data source)
* **[Apache Kafka](https://kafka.apache.org/)** â€“ Message broker for real-time data ingestion
* **[Apache Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)** â€“ Stream processing engine for data cleaning, transformation, and sentiment analysis
* **[VADER](https://github.com/cjhutto/vaderSentiment)** & **[TextBlob](https://textblob.readthedocs.io/)** â€“ Lexicon-based sentiment analysis
* **[Elasticsearch](https://www.elastic.co/elasticsearch/)** â€“ Searchable data store for storing analyzed data
* **[Kibana](https://www.elastic.co/kibana/)** â€“ Real-time analytics visualization tool for querying Elasticsearch
* **[Flask](https://flask.palletsprojects.com/)** â€“ Lightweight backend API and WebSocket server
* **[Socket.IO](https://socket.io/)** â€“ Real-time communication between backend and frontend
* **[React.js](https://reactjs.org/)** â€“ Frontend framework for real-time sentiment dashboard
* **[Recharts](https://recharts.org/)** â€“ Charting library used in the React dashboard for visualizing sentiment trends
* **[Docker](https://www.docker.com/)** â€“ Containerized deployment with multi-service orchestration

---

## ğŸš€ Getting Started

### Prerequisites

* Docker & Docker Compose
* YouTube Data API v3 key

### Installation

1. Clone this repository:

```bash
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name
```

2. Set up `.env` file with your credentials:

```env
YOUTUBE_API_KEY=your_api_key
VIDEO_ID=your_video_id
KAFKA_TOPIC=your_topic
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ docker-compose.yml               # Multi-container orchestration
â”œâ”€â”€ .env                             # Environment configuration
â”‚
â”œâ”€â”€ logs/                            # Log analysis scripts or logs
â”‚
â”œâ”€â”€ producer/                       # Kafka producer to collect YouTube live chat
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ producer.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ spark/                           # Spark job for sentiment analysis
â”‚   â”œâ”€â”€ Dockerfile                   
â”‚   â”œâ”€â”€ spark_job.py                 
â”‚   â”œâ”€â”€ requirements.txt            
â”‚   â””â”€â”€ speed_test.txt              # Performance testing log
â”‚
â”œâ”€â”€ sentiment-backend/              # Flask backend (REST API & Socket.IO)
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ sentiment-ui/                   # React.js frontend for sentiment dashboard
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ node_modules/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â”œâ”€â”€ eslint.config.js
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ img/                             # image assets
â”‚
â”œâ”€â”€ README.md                        # Main documentation
â”œâ”€â”€ How To Run (Eng).txt             # Step-by-step guide (English)
â””â”€â”€ How To Run (Idn).txt             # Step-by-step guide (Bahasa Indonesia)
```

---

## ğŸ“Œ Usage

1. Kafka producer collects YouTube Live Chat using the Data API v3.
2. Chat messages are streamed to Kafka topics in real-time.
3. Spark Structured Streaming processes messages and performs sentiment analysis.
4. Results are indexed into Elasticsearch.
5. React + Socket.IO dashboard visualizes data in near real-time.
6. Kibana dashboard allows for deeper historical analysis.

---

## ğŸ“Š Features

* â±ï¸ Near real-time ingestion of YouTube Live Chat messages
* ğŸ”„ Stream processing using Kafka & Spark Structured Streaming
* ğŸ’¬ Sentiment classification via VADER and TextBlob
* ğŸ“ˆ Live dashboard using React + Socket.IO
* ğŸ“Š Historical and advanced analytics via Kibana

![web](https://github.com/user-attachments/assets/07315439-d078-42d7-8e1c-8bd2223742e0)
![Image](https://github.com/user-attachments/assets/a44c717f-5ffc-4f4f-a730-068bee485466)
![Image](https://github.com/user-attachments/assets/e0d0ca6f-3710-4018-9cc4-d2dae758dbb9)
![kibana](https://github.com/user-attachments/assets/45075e59-c8c8-4d1f-b1db-c4159a8594d8)

---

## ğŸ§ª Testing and Performance

The system has been tested with high-traffic YouTube live streams:

| Metric                      | Result                      |
| --------------------------- | --------------------------- |
| Viewer Count (tested)       | 9K, 20K, 100K               |
| Kafka Producer Throughput   | Up to **783 messages/min**  |
| Spark Processing Rate       | Up to **14.75 batches/min** |
| End-to-End Latency          | \~**9 seconds**             |
| VADER Sentiment Accuracy    | **93%**                     |
| TextBlob Sentiment Accuracy | **60%**                     |

---

## ğŸ”® Future Improvements

* ğŸ§  Integrate deep learning models (e.g., BERT, RoBERTa)
* ğŸ” Replace API polling with WebSocket or scraping approach
* âš™ï¸ Migrate from Spark to Flink for lower-latency streaming

---

## âš ï¸ Important Notes

* Requires valid **YouTube Data API v3** key
* Configuration via `.env` file (API key, video ID, Kafka topic, etc.)

---

## ğŸ“ License

![License](https://img.shields.io/badge/license-Private_Use_Only-red.svg)

This project is licensed under a **Custom Private License**:

* For **personal, non-commercial use only**.
* Redistribution, sublicensing, or commercial usage is **not permitted**.

Copyright Â© 2025 Andrew Suadnya
