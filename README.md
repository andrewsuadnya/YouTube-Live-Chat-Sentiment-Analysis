# ğŸ“± YouTube Live Chat Sentiment Analysis (Real-Time Big Data Pipeline)

A real-time system for ingesting, processing, and analyzing YouTube Live Chat comments using modern Big Data technologies. Built using **Apache Kafka**, **Spark Structured Streaming**, **Elasticsearch**, **Kibana**, **React.js**, and **Flask**, this pipeline performs sentiment analysis using **VADER** and **TextBlob**, and visualizes results on an interactive dashboard.

---

## ğŸ”§ Tech Stack
![Data Pipeline](https://github.com/user-attachments/assets/05427a74-60b2-401d-954f-b99d7c71c7b7)

* **[Apache Kafka](https://kafka.apache.org/)** â€“ Message broker for real-time data ingestion
* **[Apache Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)** â€“ Stream processing engine
* **[Elasticsearch](https://www.elastic.co/elasticsearch/)** â€“ Searchable data store
* **[Kibana](https://www.elastic.co/kibana/)** â€“ Real-time analytics visualization tool
* **[Flask](https://flask.palletsprojects.com/)** â€“ Lightweight backend API and WebSocket server
* **[React.js](https://reactjs.org/)** â€“ Frontend for real-time sentiment dashboard
* **[Socket.IO](https://socket.io/)** â€“ Real-time messaging between backend and frontend
* **[VADER](https://github.com/cjhutto/vaderSentiment)** & **[TextBlob](https://textblob.readthedocs.io/)** â€“ Lexicon-based sentiment analysis
* **[Docker](https://www.docker.com/)** â€“ Containerized deployment with multi-service orchestration

---

## ğŸš€ Getting Started

### Prerequisites

* Docker & Docker Compose
* YouTube Data API v3 key

### Installation

1. Clone this repository:

```bash
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name
```

2. Set up `.env` file with your credentials:

```env
YOUTUBE_API_KEY=your_api_key
VIDEO_ID=your_video_id
KAFKA_TOPIC=your_topic
```

3. Run the stack:

```bash
docker-compose up --build
```

4. Access the system:

* React Dashboard â†’ [http://localhost:3000](http://localhost:3000)
* Kibana Dashboard â†’ [http://localhost:5601](http://localhost:5601)

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ spark/                      # Spark job for sentiment analysis
â”‚   â”œâ”€â”€ spark_job.py            
â”‚   â”œâ”€â”€ requirements.txt        
â”‚   â””â”€â”€ Dockerfile              
â”‚
â”œâ”€â”€ producer/                   # Kafka producer to collect YouTube live chat
â”‚   â”œâ”€â”€ producer.py             
â”‚   â”œâ”€â”€ requirements.txt        
â”‚   â””â”€â”€ Dockerfile              
â”‚
â”œâ”€â”€ logs/                       # Log analysis scripts
â”‚
â”œâ”€â”€ sentiment-backend/         # Flask backend for REST API and Socket.IO
â”‚   â””â”€â”€ app.py                  
â”‚
â”œâ”€â”€ sentiment-ui/              # React.js frontend for sentiment dashboard
â”‚   â”œâ”€â”€ src/                    
â”‚   â”œâ”€â”€ public/                 
â”‚   â””â”€â”€ index.html              
â”‚
â”œâ”€â”€ docker-compose.yml         # Multi-container orchestration
â”œâ”€â”€ README.md                  
â””â”€â”€ How To Run.txt             # Step-by-step execution guide
```

---

## ğŸ“Œ Usage

1. Kafka producer collects YouTube Live Chat using the Data API v3.
2. Chat messages are streamed to Kafka topics in real-time.
3. Spark Structured Streaming processes messages and performs sentiment analysis.
4. Results are indexed into Elasticsearch.
5. React + Socket.IO dashboard visualizes data in real-time.
6. Kibana dashboard allows for deeper historical analysis.

---

## ğŸ“Š Features

* â±ï¸ Real-time ingestion of YouTube Live Chat messages
* ğŸ”„ Stream processing using Kafka & Spark Structured Streaming
* ğŸ’¬ Sentiment classification via VADER and TextBlob
* ğŸ“ˆ Live dashboard using React + Socket.IO
* ğŸ“Š Historical and advanced analytics via Kibana

![web](https://github.com/user-attachments/assets/07315439-d078-42d7-8e1c-8bd2223742e0)
![Image](https://github.com/user-attachments/assets/a44c717f-5ffc-4f4f-a730-068bee485466)
![Image](https://github.com/user-attachments/assets/e0d0ca6f-3710-4018-9cc4-d2dae758dbb9)
![kibana](https://github.com/user-attachments/assets/45075e59-c8c8-4d1f-b1db-c4159a8594d8)

---

## ğŸ§ª Testing and Performance

The system has been tested with high-traffic YouTube live streams:

| Metric                      | Result                      |
| --------------------------- | --------------------------- |
| Viewer Count (tested)       | 9K, 20K, 100K               |
| Kafka Producer Throughput   | Up to **783 messages/min**  |
| Spark Processing Rate       | Up to **14.75 batches/min** |
| End-to-End Latency          | \~**9 seconds**             |
| VADER Sentiment Accuracy    | **93%**                     |
| TextBlob Sentiment Accuracy | **60%**                     |

---

## ğŸ”® Future Improvements

* ğŸ§  Integrate deep learning models (e.g., BERT, RoBERTa)
* ğŸ” Replace API polling with WebSocket or scraping approach
* âš™ï¸ Migrate from Spark to Flink for lower-latency streaming

---

## âš ï¸ Important Notes

* Requires valid **YouTube Data API v3** key
* Configuration via `.env` file (API key, video ID, Kafka topic, etc.)

---

## ğŸ“ License

This project is licensed under the [MIT License](LICENSE).
